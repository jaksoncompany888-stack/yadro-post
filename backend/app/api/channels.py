"""
Channels API

–ê–Ω–∞–ª–∏–∑ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Telegram –∫–∞–Ω–∞–ª–∞–º–∏.
–ö–∞–Ω–∞–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –ë–î –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ –∫ user_id.
"""

from typing import Optional, List
from pydantic import BaseModel

from fastapi import APIRouter, HTTPException, Depends

from app.tools.channel_parser import ChannelParser
from app.api.deps import get_current_user, get_db
from app.memory import MemoryService, MemoryType


router = APIRouter(prefix="/channels", tags=["channels"])


# =============================================================================
# Models
# =============================================================================

class ChannelInfo(BaseModel):
    username: str
    title: str
    subscribers: int
    description: str


class ChannelMetrics(BaseModel):
    posts_analyzed: int
    avg_length: int
    length_category: str
    avg_emoji: float
    emoji_style: str
    avg_hashtags: float
    top_hashtags: List[str]
    structure: List[str]
    hook_patterns: List[str]
    cta_style: str
    top_words: List[str]
    avg_views: int
    max_views: int
    min_views: int
    avg_reactions: int
    total_reactions: int
    avg_forwards: int
    engagement_rate: float
    recommended_temperature: float
    content_type: str


class ChannelAnalysis(BaseModel):
    channel: ChannelInfo
    metrics: ChannelMetrics
    examples: dict


class AnalyzeRequest(BaseModel):
    channel: str  # @username –∏–ª–∏ username
    limit: int = 30  # –ë–æ–ª—å—à–µ –ø–æ—Å—Ç–æ–≤ = –ª—É—á—à–µ –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ç–µ–º
    save_to_memory: bool = True  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∞–Ω–∞–ª–∏–∑ –≤ –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è


# =============================================================================
# Endpoints
# =============================================================================

@router.post("/analyze", response_model=ChannelAnalysis)
async def analyze_channel(
    data: AnalyzeRequest,
    db=Depends(get_db),
    current_user: dict = Depends(get_current_user)
):
    """
    –ê–Ω–∞–ª–∏–∑ Telegram –∫–∞–Ω–∞–ª–∞.

    –ü–∞—Ä—Å–∏—Ç –ø–æ—Å—Ç—ã –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏:
    - –î–ª–∏–Ω–∞ –ø–æ—Å—Ç–æ–≤, —ç–º–æ–¥–∑–∏, —Ö–µ—à—Ç–µ–≥–∏
    - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (—Å–ø–∏—Å–∫–∏, –∞–±–∑–∞—Ü—ã)
    - –•—É–∫–∏ –∏ CTA
    - –ü—Ä–æ—Å–º–æ—Ç—Ä—ã, —Ä–µ–∞–∫—Ü–∏–∏, engagement
    - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è temperature –¥–ª—è AI

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤ –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤.
    """
    parser = ChannelParser()
    user_id = current_user["id"]

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ
        info = parser.get_channel_info(data.channel)

        # –ü–∞—Ä—Å–∏–º –ø–æ—Å—Ç—ã
        posts = parser.parse_channel(data.channel, limit=data.limit)

        if not posts:
            raise HTTPException(
                status_code=404,
                detail="–ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ö–∞–Ω–∞–ª –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –∏–ª–∏ –ø—É—Å—Ç–æ–π."
            )

        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        posts_data = [
            {
                "text": p.text,
                "views": p.views,
                "reactions": p.reactions,
                "forwards": p.forwards,
            }
            for p in posts
        ]

        metrics = _compute_metrics(posts_data)

        # –§–æ—Ä–º–∏—Ä—É–µ–º username
        username = data.channel.replace("@", "").replace("https://t.me/", "")

        analysis = ChannelAnalysis(
            channel=ChannelInfo(
                username=username,
                title=info["title"],
                subscribers=info["subscribers"],
                description=info["description"],
            ),
            metrics=ChannelMetrics(
                posts_analyzed=metrics["posts_analyzed"],
                **metrics["metrics"]
            ),
            examples=metrics["examples"],
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if data.save_to_memory:
            memory = MemoryService(db=db)

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª—è –¥–ª—è –ø–∞–º—è—Ç–∏
            # –í–ê–ñ–ù–û: –¥–æ–±–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è FTS5 –ø–æ–∏—Å–∫–∞
            m = metrics["metrics"]
            description_clean = info.get('description', '')[:200] if info.get('description') else ''
            style_content = f"""–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ @{username}:
üìä {info['title']} ({info['subscribers']} –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤)
–¢–µ–º–∞—Ç–∏–∫–∞: {description_clean}
–î–ª–∏–Ω–∞ –ø–æ—Å—Ç–æ–≤: {m['length_category']} (~{m['avg_length']} —Å–∏–º–≤–æ–ª–æ–≤)
–≠–º–æ–¥–∑–∏: {m['emoji_style']} ({m['avg_emoji']} –≤ —Å—Ä–µ–¥–Ω–µ–º)
–°—Ç—Ä—É–∫—Ç—É—Ä–∞: {', '.join(m['structure'])}
–•—É–∫–∏: {', '.join(m['hook_patterns'])}
CTA: {m['cta_style']}
–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {m['content_type']}
Engagement: {m['engagement_rate']}%
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(m['top_words'][:10])}"""

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —ç—Ç–æ–≥–æ –∫–∞–Ω–∞–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            db.execute(
                "DELETE FROM memory_items WHERE user_id = ? AND content LIKE ?",
                (user_id, f"–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ @{username}%")
            )
            # –£–¥–∞–ª—è–µ–º –∏–∑ FTS
            db.execute(
                """DELETE FROM memory_fts WHERE rowid IN (
                    SELECT id FROM memory_items WHERE user_id = ? AND content LIKE ?
                )""",
                (user_id, f"–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ @{username}%")
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            memory.store(
                user_id=user_id,
                content=style_content,
                memory_type=MemoryType.CONTEXT,
                importance=0.85,
                metadata={
                    "channel": f"@{username}",
                    "recommended_temperature": m["recommended_temperature"],
                    "content_type": m["content_type"],
                    "analysis_version": "v2"
                }
            )

        return analysis

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("", response_model=List[ChannelInfo])
async def list_channels(
    db=Depends(get_db),
    current_user: dict = Depends(get_current_user)
):
    """–°–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_id = current_user["id"]

    rows = db.fetch_all(
        "SELECT username, title, subscribers, description FROM competitor_channels WHERE user_id = ?",
        (user_id,)
    )

    return [
        ChannelInfo(
            username=row["username"],
            title=row["title"] or row["username"],
            subscribers=row["subscribers"] or 0,
            description=row["description"] or ""
        )
        for row in rows
    ]


@router.post("/add")
async def add_channel(
    data: AnalyzeRequest,
    db=Depends(get_db),
    current_user: dict = Depends(get_current_user)
):
    """
    –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª –≤ —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (—Å –ø–æ–ª—É—á–µ–Ω–∏–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏).
    """
    parser = ChannelParser()
    user_id = current_user["id"]

    try:
        info = parser.get_channel_info(data.channel)
        username = data.channel.replace("@", "").replace("https://t.me/", "")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î (INSERT OR REPLACE –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å)
        # Database.execute() –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–µ—Ç commit
        db.execute(
            """INSERT OR REPLACE INTO competitor_channels
               (user_id, username, title, subscribers, description)
               VALUES (?, ?, ?, ?, ?)""",
            (user_id, username, info["title"], info["subscribers"], info["description"])
        )

        channel = ChannelInfo(
            username=username,
            title=info["title"],
            subscribers=info["subscribers"],
            description=info["description"],
        )

        return {"status": "added", "channel": channel}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/{username}")
async def remove_channel(
    username: str,
    db=Depends(get_db),
    current_user: dict = Depends(get_current_user)
):
    """–£–¥–∞–ª–∏—Ç—å –∫–∞–Ω–∞–ª –∏–∑ —Å–ø–∏—Å–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""
    user_id = current_user["id"]

    # Database.execute() –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–µ—Ç commit
    db.execute(
        "DELETE FROM competitor_channels WHERE user_id = ? AND username = ?",
        (user_id, username)
    )

    return {"status": "removed"}


# =============================================================================
# Helpers
# =============================================================================

def _compute_metrics(posts: List[dict]) -> dict:
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞–Ω–∞–ª–∞ –±–µ–∑ LLM.
    –ö–æ–ø–∏—è –∏–∑ smm_tools.py –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
    """
    import re
    from collections import Counter

    if not posts:
        return {"error": "no posts"}

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∫–ª–∞–º—É
    ad_markers = ['#—Ä–µ–∫–ª–∞–º–∞', '#ad', '–ø—Ä–æ–º–æ–∫–æ–¥', '—Å–∫–∏–¥–∫–∞', '–∫—É–ø–∏—Ç—å']
    organic = [p for p in posts if not any(m in p.get('text', '').lower() for m in ad_markers)]

    if not organic:
        organic = posts[:5]

    texts = [p.get('text', '') for p in organic]

    # === –ú–ï–¢–†–ò–ö–ò ===

    # 1. –î–ª–∏–Ω–∞ –ø–æ—Å—Ç–æ–≤
    lengths = [len(t) for t in texts]
    avg_length = sum(lengths) // len(lengths) if lengths else 0
    length_category = "–∫–æ—Ä–æ—Ç–∫–∏–µ" if avg_length < 300 else "—Å—Ä–µ–¥–Ω–∏–µ" if avg_length < 800 else "–¥–ª–∏–Ω–Ω—ã–µ"

    # 2. –≠–º–æ–¥–∑–∏
    emoji_pattern = re.compile(r'[\U0001F300-\U0001F9FF\u2600-\u26FF\u2700-\u27BF]')
    emoji_counts = [len(emoji_pattern.findall(t)) for t in texts]
    avg_emoji = sum(emoji_counts) / len(emoji_counts) if emoji_counts else 0
    emoji_style = "–º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏" if avg_emoji > 3 else "–º–∞–ª–æ —ç–º–æ–¥–∑–∏" if avg_emoji > 0 else "–±–µ–∑ —ç–º–æ–¥–∑–∏"

    # 3. –•–µ—à—Ç–µ–≥–∏
    hashtag_pattern = re.compile(r'#\w+')
    hashtag_counts = [len(hashtag_pattern.findall(t)) for t in texts]
    avg_hashtags = sum(hashtag_counts) / len(hashtag_counts) if hashtag_counts else 0
    all_hashtags = []
    for t in texts:
        all_hashtags.extend(hashtag_pattern.findall(t))
    top_hashtags = [h for h, _ in Counter(all_hashtags).most_common(5)]

    # 4. –°—Ç—Ä—É–∫—Ç—É—Ä–∞
    has_lists = sum(1 for t in texts if re.search(r'(^|\n)[‚Ä¢\-\d]\s', t)) / len(texts) > 0.3
    has_paragraphs = sum(1 for t in texts if t.count('\n\n') >= 2) / len(texts) > 0.3
    structure = []
    if has_lists:
        structure.append("—Å–ø–∏—Å–∫–∏")
    if has_paragraphs:
        structure.append("–∞–±–∑–∞—Ü—ã")
    if not structure:
        structure.append("—Å–ø–ª–æ—à–Ω–æ–π —Ç–µ–∫—Å—Ç")

    # 5. –°—Ç–∞—Ä—Ç–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (hooks)
    first_lines = [t.split('\n')[0][:50] for t in texts if t]
    hook_patterns = []
    question_hooks = sum(1 for l in first_lines if '?' in l)
    if question_hooks >= 2:
        hook_patterns.append("–≤–æ–ø—Ä–æ—Å—ã")
    emoji_hooks = sum(1 for l in first_lines if emoji_pattern.search(l))
    if emoji_hooks >= 2:
        hook_patterns.append("—ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ")
    caps_hooks = sum(1 for l in first_lines if l.isupper() or l[:10].isupper())
    if caps_hooks >= 2:
        hook_patterns.append("–ö–ê–ü–°")

    # 6. –ö–æ–Ω—Ü–æ–≤–∫–∏ (CTA)
    last_lines = [t.strip().split('\n')[-1] for t in texts if t]
    cta_keywords = ['–ø–æ–¥–ø–∏—Å—ã', '—Å—Ç–∞–≤—å', '–ø–∏—à–∏', '–¥–µ–ª–∏—Å—å', '—Ä–µ–ø–æ—Å—Ç', '–∫–æ–º–µ–Ω—Ç', '—Å—Å—ã–ª–∫']
    has_cta = sum(1 for l in last_lines if any(k in l.lower() for k in cta_keywords))
    cta_style = "–µ—Å—Ç—å CTA" if has_cta >= 2 else "–±–µ–∑ CTA"

    # 7. –¢–æ–ø —Å–ª–æ–≤–∞
    stop_words = {'–∏', '–≤', '–Ω–∞', '—Å', '—á—Ç–æ', '—ç—Ç–æ', '–∫–∞–∫', '–∞', '–Ω–µ', '–Ω–æ', '–¥–ª—è', '–ø–æ', '–∫', '–∏–∑', '—É', '–æ', '–∂–µ', '—Ç–æ', '–≤—Å–µ', '—Ç–∞–∫', '–µ–≥–æ', '–æ—Ç', '–æ–Ω–∏', '–≤—ã', '–º—ã', '—è', '–±—ã', '–æ–Ω', '–æ–Ω–∞', '–±—ã–ª–æ', '–±—ã—Ç—å', '–∏–ª–∏', '–ø—Ä–∏', '—É–∂–µ', '–µ—Å–ª–∏', '–∏—Ö', '–µ–µ', '–µ—ë', '—Ç–æ–ª—å–∫–æ', '–∫–æ–≥–¥–∞', '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–∏', '–≤–æ—Ç', '—Ç—É—Ç', '—Ç–∞–º', '—Ç—ã', '–∑–∞'}
    all_words = []
    for t in texts:
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Åa-zA-Z]{4,}\b', t.lower())
        all_words.extend([w for w in words if w not in stop_words])
    top_words = [w for w, _ in Counter(all_words).most_common(10)]

    # 8. –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
    views = [p.get('views', 0) for p in organic if p.get('views')]
    avg_views = sum(views) // len(views) if views else 0
    max_views = max(views) if views else 0
    min_views = min(views) if views else 0

    # 9. –†–µ–∞–∫—Ü–∏–∏
    reactions = [p.get('reactions', 0) for p in organic]
    avg_reactions = sum(reactions) // len(reactions) if reactions else 0
    total_reactions = sum(reactions)

    # 10. –†–µ–ø–æ—Å—Ç—ã
    forwards = [p.get('forwards', 0) for p in organic]
    avg_forwards = sum(forwards) // len(forwards) if forwards else 0

    # 11. Engagement rate
    engagement = 0
    if avg_views > 0:
        engagement = round((avg_reactions + avg_forwards) / avg_views * 100, 2)

    # === TEMPERATURE ===
    recommended_temperature = 0.5
    content_type = "—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π"

    if avg_length > 500 and avg_emoji < 1.5 and "–≤–æ–ø—Ä–æ—Å—ã" not in hook_patterns:
        recommended_temperature = 0.3
        content_type = "–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π"
    elif avg_length < 300 and (avg_emoji > 1.5 or "–≤–æ–ø—Ä–æ—Å—ã" in hook_patterns):
        recommended_temperature = 0.7
        content_type = "–ª–∞–π—Ñ—Å—Ç–∞–π–ª"
    elif avg_emoji < 0.5 and cta_style == "–±–µ–∑ CTA":
        recommended_temperature = 0.35
        content_type = "–Ω–æ–≤–æ—Å—Ç–Ω–æ–π"
    elif avg_emoji > 2 and cta_style == "–µ—Å—Ç—å CTA":
        recommended_temperature = 0.6
        content_type = "–∞–≤—Ç–æ—Ä—Å–∫–∏–π"

    return {
        "posts_analyzed": len(organic),
        "metrics": {
            "avg_length": avg_length,
            "length_category": length_category,
            "avg_emoji": round(avg_emoji, 1),
            "emoji_style": emoji_style,
            "avg_hashtags": round(avg_hashtags, 1),
            "top_hashtags": top_hashtags,
            "structure": structure,
            "hook_patterns": hook_patterns or ["–±–µ–∑ —è–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"],
            "cta_style": cta_style,
            "top_words": top_words,
            "avg_views": avg_views,
            "max_views": max_views,
            "min_views": min_views,
            "avg_reactions": avg_reactions,
            "total_reactions": total_reactions,
            "avg_forwards": avg_forwards,
            "engagement_rate": engagement,
            "recommended_temperature": recommended_temperature,
            "content_type": content_type,
        },
        "examples": {
            "hooks": first_lines[:3],
            "endings": last_lines[:3],
        }
    }
